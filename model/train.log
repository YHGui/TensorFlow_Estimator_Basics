Using default config.
Using config: {'_model_dir': 'model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fbae3ff3f98>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
From /home/leimao/.local/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
From /home/leimao/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py:494: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
Calling model_fn.
From /home/leimao/Workspace/tf-estimator-basics/model.py:15: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
From /home/leimao/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
From /home/leimao/Workspace/tf-estimator-basics/model.py:29: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

From /home/leimao/Workspace/tf-estimator-basics/model.py:30: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.

Done calling model_fn.
Create CheckpointSaverHook.
From /home/leimao/.local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
Graph was finalized.
Running local_init_op.
Done running local_init_op.
Saving checkpoints for 0 into model/model.ckpt.
loss = 208.61423, step = 1
global_step/sec: 244.359
loss = 63.928616, step = 101 (0.410 sec)
global_step/sec: 140.962
loss = 294.5415, step = 201 (0.709 sec)
global_step/sec: 119.423
loss = 92.28231, step = 301 (0.837 sec)
global_step/sec: 119.479
loss = 20.433266, step = 401 (0.837 sec)
global_step/sec: 168.033
loss = 608.985, step = 501 (0.594 sec)
global_step/sec: 628.966
loss = 26457.914, step = 601 (0.159 sec)
global_step/sec: 545.548
loss = 5734.4985, step = 701 (0.184 sec)
global_step/sec: 435.928
loss = 2002.7314, step = 801 (0.229 sec)
global_step/sec: 790.929
loss = 573.34106, step = 901 (0.126 sec)
Saving checkpoints for 1000 into model/model.ckpt.
Loss for final step: 28.499075.
Using default config.
Using config: {'_model_dir': 'model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f225d291f98>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
From /home/leimao/.local/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
From /home/leimao/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py:494: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
Calling model_fn.
From /home/leimao/Workspace/tf-estimator-basics/model.py:15: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
From /home/leimao/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
From /home/leimao/Workspace/tf-estimator-basics/model.py:29: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

From /home/leimao/Workspace/tf-estimator-basics/model.py:30: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.

Done calling model_fn.
Create CheckpointSaverHook.
From /home/leimao/.local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
Graph was finalized.
From /home/leimao/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
Restoring parameters from model/model.ckpt-1000
From /home/leimao/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1066: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
Running local_init_op.
Done running local_init_op.
Saving checkpoints for 1000 into model/model.ckpt.
loss = 133.1843, step = 1001
global_step/sec: 381.643
loss = 25.091991, step = 1101 (0.262 sec)
global_step/sec: 801.976
loss = 3.8875227, step = 1201 (0.124 sec)
global_step/sec: 847.394
loss = 0.5002587, step = 1301 (0.118 sec)
global_step/sec: 664.477
loss = 0.053553894, step = 1401 (0.151 sec)
global_step/sec: 471.255
loss = 0.0047466117, step = 1501 (0.212 sec)
global_step/sec: 438.781
loss = 0.00034424692, step = 1601 (0.228 sec)
global_step/sec: 561.222
loss = 2.0050507e-05, step = 1701 (0.178 sec)
global_step/sec: 766.919
loss = 9.5025234e-07, step = 1801 (0.130 sec)
global_step/sec: 592.024
loss = 8.275947e-08, step = 1901 (0.169 sec)
Saving checkpoints for 2000 into model/model.ckpt.
Loss for final step: 7.566996e-09.
