Using default config.
Using config: {'_model_dir': 'model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7c428c5ac8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
From /home/leimao/.local/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
From /home/leimao/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py:494: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
Calling model_fn.
From /home/leimao/GitHub/tf-estimator-basics/model.py:15: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
From /home/leimao/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
From /home/leimao/GitHub/tf-estimator-basics/model.py:26: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

From /home/leimao/GitHub/tf-estimator-basics/model.py:27: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.

Done calling model_fn.
Create CheckpointSaverHook.
From /home/leimao/.local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
Graph was finalized.
Running local_init_op.
Done running local_init_op.
Saving checkpoints for 0 into model/model.ckpt.
loss = 11702.148, step = 1
global_step/sec: 173.854
loss = 19.716768, step = 101 (0.576 sec)
global_step/sec: 179.148
loss = 1.9883475, step = 201 (0.558 sec)
global_step/sec: 182.582
loss = 1.1419557, step = 301 (0.548 sec)
global_step/sec: 181.332
loss = 0.8600235, step = 401 (0.551 sec)
global_step/sec: 174.728
loss = 0.18825576, step = 501 (0.572 sec)
global_step/sec: 180.284
loss = 0.011629508, step = 601 (0.555 sec)
global_step/sec: 175.972
loss = 0.0023516174, step = 701 (0.568 sec)
global_step/sec: 187.468
loss = 0.00029132262, step = 801 (0.534 sec)
global_step/sec: 176.207
loss = 121.89046, step = 901 (0.567 sec)
Saving checkpoints for 1000 into model/model.ckpt.
Loss for final step: 0.5116225.
